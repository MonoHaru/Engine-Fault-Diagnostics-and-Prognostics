{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " C ����̺��� �������� �̸��� �����ϴ�.\n",
      " ���� �Ϸ� ��ȣ: 8407-609B\n",
      "\n",
      " c:\\Users\\Sejong\\OneDrive - Sejong University\\����\\īī���� ���� ����\\hanhwa_04_01 ���͸�\n",
      "\n",
      "2024-04-01  ���� 10:39    <DIR>          .\n",
      "2024-09-20  ���� 09:43    <DIR>          ..\n",
      "2024-04-01  ���� 10:39                 0 __init__.py\n",
      "2024-04-01  ���� 10:39           643,753 03_13.ipynb\n",
      "2024-04-01  ���� 10:39         1,849,760 03_28.ipynb\n",
      "2024-04-01  ���� 10:39           158,077 11_29_trans_single.ipynb\n",
      "2024-09-20  ���� 09:44             6,869 12_12_lstm_multistep.ipynb\n",
      "2024-04-01  ���� 10:39             7,581 12_19_final.ipynb\n",
      "2024-04-01  ���� 10:39    <DIR>          final_functions\n",
      "2024-04-01  ���� 10:39    <DIR>          function_file\n",
      "2024-04-01  ���� 10:39           118,722 machine_learning.ipynb\n",
      "2024-04-01  ���� 10:39    <DIR>          model\n",
      "2024-04-01  ���� 10:39    <DIR>          new_temp_file\n",
      "2024-04-01  ���� 10:39                69 README.md\n",
      "2024-04-01  ���� 10:39                44 requirements.txt\n",
      "2024-04-01  ���� 10:39    <DIR>          temp_add_gps\n",
      "2024-04-01  ���� 10:39    <DIR>          temperature_csv_file\n",
      "2024-04-01  ���� 10:39    <DIR>          thesis\n",
      "2024-04-01  ���� 10:39    <DIR>          thesis_functions\n",
      "2024-04-01  ���� 10:39    <DIR>          tmp\n",
      "2024-04-01  ���� 10:39            10,072 transformer_multivariate_prediction_12_05.ipynb\n",
      "2024-04-01  ���� 10:39             4,627 transformer_multivarite_prediction.ipynb\n",
      "2024-04-01  ���� 10:39    <DIR>          weights\n",
      "2024-04-01  ���� 10:39    <DIR>          ��¥����\n",
      "2024-04-01  ���� 10:39    <DIR>          ����csv����\n",
      "2024-04-01  ���� 10:39    <DIR>          ��������\n",
      "              11�� ����           2,799,574 ����Ʈ\n",
      "              15�� ���͸�  159,281,545,216 ����Ʈ ����\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sejong\\anaconda3\\envs\\web2n\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import function_file as ff\n",
    "from function_file.time_series import time_series_dataframe\n",
    "df = time_series_dataframe()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy as dc\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "def multistep_time_series(input_data, input_window, output_window):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-input_window):\n",
    "        train_seq = np.append(input_data[i:i+input_window][:-output_window] , output_window * [0])\n",
    "        train_label = input_data[i:i+input_window]\n",
    "        #train_label = input_data[i+output_window:i+tw+output_window]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return torch.FloatTensor(inout_seq)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df = df['TEMP'].values\n",
    "train_len = int(len(df) * 0.7)\n",
    "train = df[:train_len]\n",
    "test = df[train_len:]\n",
    "input_window =100\n",
    "output_window = 60\n",
    "\n",
    "train_data = multistep_time_series(train, input_window, output_window)\n",
    "test_data = multistep_time_series(test, input_window, output_window)\n",
    "train_data = train_data[:-output_window]\n",
    "test_data = test_data[:-output_window]\n",
    "train_data = train_data.to(device)\n",
    "test_data = test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 512\n",
    "train_dataloader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader(test_data, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class LSTM_ms(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_stacked_layers):\n",
    "        super(LSTM_ms, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_stacked_layers = num_stacked_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_stacked_layers, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from helper import series_to_supervised, mean_absolute_percentage_error\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(65, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(train_y.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanhwa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
